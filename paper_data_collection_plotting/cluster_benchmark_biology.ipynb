{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SAM import SAM\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics as met\n",
    "import utilities as ut\n",
    "import utilities_full as ut2\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import pickle\n",
    "\n",
    "def DARMANIS(**kwargs):\n",
    "    sam = SAM()\n",
    "    sam.load_data('darmanis/darmanis_data.csv', **kwargs)\n",
    "    sam.load_obs_annotations('darmanis/darmanis_ann.csv')\n",
    "    sam.preprocess_data()\n",
    "    return sam\n",
    "\n",
    "def WANG(**kwargs):\n",
    "    sam = SAM()\n",
    "    sam.load_data('final_datasets/GSE83139/wang_data_sparse.p', **kwargs)\n",
    "    sam.preprocess_data(filter_genes=False,min_expression=1)\n",
    "    A = pd.read_csv('final_datasets/GSE83139/wang_ann.csv',header=None,index_col=0)    \n",
    "    A.index = A.index.astype(\"<U100\")\n",
    "    sam.adata.obs['ann'] = A\n",
    "    sam.adata.var_names_make_unique()\n",
    "    return sam\n",
    "\n",
    "def human1(**kwargs):\n",
    "    sam = SAM()\n",
    "    sam.load_data('final_datasets/GSE84133_1/human1_sparse.p')\n",
    "    sam.preprocess_data()\n",
    "    sam.load_obs_annotations('final_datasets/GSE84133_1/human1_ann.csv')\n",
    "    return sam\n",
    "\n",
    "\n",
    "def human2(**kwargs):\n",
    "    sam = SAM()\n",
    "    sam.load_data('final_datasets/GSE84133_2/human2_sparse.p')\n",
    "    sam.preprocess_data()\n",
    "    sam.load_obs_annotations('final_datasets/GSE84133_2/human2_ann.csv')\n",
    "    return sam\n",
    "\n",
    "def human3(**kwargs):\n",
    "    sam = SAM()\n",
    "    sam.load_data('final_datasets/GSE84133_3/human3_sparse.p')\n",
    "    sam.preprocess_data()\n",
    "    sam.load_obs_annotations('final_datasets/GSE84133_3/human3_ann.csv')\n",
    "    return sam\n",
    "def human4(**kwargs):\n",
    "    sam = SAM()\n",
    "    sam.load_data('final_datasets/GSE84133_4/human4_sparse.p')\n",
    "    sam.preprocess_data()\n",
    "    sam.load_obs_annotations('final_datasets/GSE84133_4/human4_ann.csv')\n",
    "    return sam\n",
    "\n",
    "\n",
    "def KOH(**kwargs):\n",
    "    sam = SAM()\n",
    "    sam.load_data('final_datasets/SRP073808/SRP073808_data.csv',\n",
    "                            **kwargs)\n",
    "    sam.load_obs_annotations('final_datasets/SRP073808/SRP073808_ann.csv')\n",
    "    sam.preprocess_data()\n",
    "    return sam\n",
    "\n",
    "\n",
    "def SEGER(**kwargs):\n",
    "    sam=SAM()\n",
    "    sam.load_data('final_datasets/seger/seger_sparse.p')\n",
    "    sam.load_obs_annotations('final_datasets/seger/seger_ann.csv')\n",
    "    sam.preprocess_data()\n",
    "    return sam\n",
    "\n",
    "\n",
    "def MURARO(**kwargs):\n",
    "    sam=SAM()\n",
    "    sam.load_data('final_datasets/muraro/muraro_sparse.p')\n",
    "    sam.load_obs_annotations('final_datasets/muraro/muraro_ann.csv')\n",
    "    sam.preprocess_data()\n",
    "    return sam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import rpy2.robjects as robjects\n",
    "from rpy2.robjects.packages import importr\n",
    "import rpy2.robjects.numpy2ri\n",
    "from rpy2.robjects import r\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "StrVector = robjects.StrVector\n",
    "rpy2.robjects.numpy2ri.activate()\n",
    "SingleCellExperiment = r(''' \n",
    "  f <- function(x){\n",
    "    sce <- SingleCellExperiment(assays = list(counts = x))\n",
    "  }\n",
    "  ''')\n",
    "\n",
    "SC3 = r(''' \n",
    "        function(data,genes,k,genefilter){\n",
    "              sce <- SingleCellExperiment(\n",
    "                assays = list(\n",
    "                  counts = data,\n",
    "                  logcounts = log2(data + 1)\n",
    "                )\n",
    "              )\n",
    "              rowData(sce)$feature_symbol <- genes\n",
    "              sce <- sce[!duplicated(rowData(sce)$feature_symbol), ]\n",
    "              if(k==0){\n",
    "                  sce <- sc3_estimate_k(sce)\n",
    "                  k <- metadata(sce)$sc3$k_estimation\n",
    "                  if (k > 50){\n",
    "                  k = 50\n",
    "                  }\n",
    "                 }\n",
    "              print(k)\n",
    "              sce <- sc3(sce, ks = k, biology = FALSE,gene_filter=genefilter)\n",
    "              col_data <- as.matrix(colData(sce))\n",
    "              nlist <- list(\"rdata\" = col_data, \"k\" = k)\n",
    "         }\n",
    "        ''')\n",
    "\n",
    "\n",
    "SIMLR = r('''\n",
    "          function(data,genes,k){\n",
    "              b<-as.data.frame(data)\n",
    "              rownames(b)<-genes\n",
    "              if(k==0){\n",
    "                  NUMC = 2:10\n",
    "                  res_example = SIMLR_Estimate_Number_of_Clusters(X = b,NUMC=NUMC,cores.ratio=1)            \n",
    "                  c1=NUMC[which.min(res_example$K1)]\n",
    "                  c2=NUMC[which.min(res_example$K2)]\n",
    "                  c = min(c(c1,c2))\n",
    "              }else{\n",
    "                      c=k\n",
    "              }\n",
    "              if( c > 50){\n",
    "              c = 50\n",
    "              \n",
    "              }\n",
    "              print(c)              \n",
    "              \n",
    "              res_hsc <- SIMLR(X =  b, normalize = T, c = c)\n",
    "              res_hsc\n",
    "        \n",
    "              nlist <- list(\"rdata\" = res_hsc, \"k\" = c)\n",
    "          }\n",
    "\n",
    "          ''')\n",
    "SCE = importr('SingleCellExperiment')\n",
    "scater = importr('scater')\n",
    "simlr = importr('SIMLR')\n",
    "sc3 = importr('SC3')\n",
    "\n",
    "def SEURAT(adata):\n",
    "    pca,_,_,_ = ut2.do_SEURAT4(adata.copy(),NN=3000)\n",
    "    cl = hdbknn(Normalizer().fit_transform(pca))\n",
    "    return pca,cl\n",
    "\n",
    "def SEURAT2(adata,ng,npc):\n",
    "    pca,_,_,_ = ut2.do_SEURAT4(adata.copy(),npcs=npc,NN=ng)\n",
    "    cl = hdbknn(Normalizer().fit_transform(pca))\n",
    "    return pca,cl\n",
    "\n",
    "def hdbknn(X):\n",
    "    import hdbscan\n",
    "    k=20\n",
    "\n",
    "    hdb = hdbscan.HDBSCAN(metric='euclidean')\n",
    "\n",
    "    cl = hdb.fit_predict(Normalizer().fit_transform(X))\n",
    "\n",
    "    idx0 = np.where(cl != -1)[0]\n",
    "    idx1 = np.where(cl == -1)[0]\n",
    "    if idx1.size > 0 and idx0.size > 0:\n",
    "        xcmap = ut.generate_euclidean_map(X[idx0, :], X[idx1, :])\n",
    "        knn = np.argsort(xcmap.T, axis=1)[:, :k]\n",
    "        nnm = np.zeros(xcmap.shape).T\n",
    "        nnm[np.tile(np.arange(knn.shape[0])[:, None],\n",
    "                    (1, knn.shape[1])).flatten(),\n",
    "            knn.flatten()] = 1\n",
    "        nnmc = np.zeros((nnm.shape[0], cl.max() + 1))\n",
    "        for i in range(cl.max() + 1):\n",
    "            nnmc[:, i] = nnm[:, cl[idx0] == i].sum(1)\n",
    "\n",
    "        cl[idx1] = np.argmax(nnmc, axis=1)\n",
    "\n",
    "    return cl\n",
    "def ari(x, y):\n",
    "    return met.adjusted_rand_score(x, y)\n",
    "def colabeling(a,b):\n",
    "    au,acu = np.unique(a,return_counts=True)\n",
    "    bu,bcu = np.unique(b,return_counts=True)\n",
    "    co = np.zeros((au.size,bu.size))\n",
    "    \n",
    "    for i in range(bu.size):\n",
    "        x1,x2 = np.unique(a[b==bu[i]],return_counts=True)\n",
    "        co[np.in1d(au,x1),i] += x2# / bcu[i]\n",
    "    #coa = co*1/acu[:,None]\n",
    "    #cob = co*1/bcu[None,:]\n",
    "\n",
    "    midx = np.argmax(co,axis=0)\n",
    "    scores=np.zeros(midx.size)\n",
    "    for i in range(midx.size):\n",
    "        #scores[i] = (co[midx[i],i]/co[:,i].sum() + co[midx[i],i]/co[midx[i],:].sum())/2    \n",
    "        scores[i] = co[midx[i],i] / max(bcu[i],acu[midx[i]])        \n",
    "    return co,scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting sparse matrix to csr format...\n",
      "Converting sparse matrix to csr format...\n"
     ]
    }
   ],
   "source": [
    "preproc = ['Normalizer','Normalizer']+['StandardScaler',]*4+['Normalizer',]*3\n",
    "funcs = [DARMANIS(),WANG(),human1(),human2(),human3(),human4(),KOH(),SEGER(),MURARO()]\n",
    "names = ['DARMANIS','WANG','human1','human2','human3','human4','KOH','SEGER','MURARO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngenes = [500,1000,1500,2000,2500,3000,3500,4000,4500,5000,5500,6000,6500,7000,-1]\n",
    "npcs = [6,10,15,20,25,30,35,40,45,50]\n",
    "RECORDd = pickle.load(open('paper_scripts/seurat_param_sweep_bigger_fixed.p','rb'))\n",
    "nge=[]\n",
    "npc=[]\n",
    "for i in names:\n",
    "    ind = np.where(RECORDd[i]>= RECORDd[i].max())\n",
    "    n1,n2 = ngenes[ind[0][0]],npcs[ind[1][0]]\n",
    "    nge.append(n1)\n",
    "    npc.append(n2)\n",
    "    \n",
    "nge[1]=3000\n",
    "npc[1]=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(AMIsc,AMIsi) = pickle.load(open('paper_scripts/amiari_sc3sim_uncorrupted2.p','rb'))\n",
    "AMIsc = AMIsc[:,np.arange(10)!=7]\n",
    "AMIsi = AMIsi[:,np.arange(10)!=7]\n",
    "ksc = AMIsc[-1,:]\n",
    "ksi = AMIsi[-1,:]\n",
    "\n",
    "C1=[]\n",
    "C2=[]\n",
    "C3=[]\n",
    "for I in range(len(names)):\n",
    "    print(names[I])\n",
    "    sam = funcs[I]\n",
    "    \n",
    "    ge = np.array(list(sam.adata.var_names))\n",
    "    \n",
    "    print('SC3')    \n",
    "    if names[I] == 'WANG':\n",
    "        cluster_labels1 = list(list(SC3(sam.adata_raw.X.A.T,ge,ksc[I],False))[0])\n",
    "    else:\n",
    "        cluster_labels1 = list(list(SC3(sam.adata_raw.X.A.T,ge,ksc[I],True))[0])\n",
    "        \n",
    "    print('SIMLR')\n",
    "    cluster_labels2 = list(list(SIMLR(sam.adata.X.A.T,ge,ksi[I]))[0][0][0])\n",
    "    print('Seurat')\n",
    "    _,cluster_labels3 = SEURAT(sam.adata_raw.copy())\n",
    "    \n",
    "    C1.append(cluster_labels1)\n",
    "    C2.append(cluster_labels2)\n",
    "    C3.append(cluster_labels3)\n",
    "    \n",
    "    print('SC3 - ' + str(ari(funcs[I].adata.obs.iloc[:,0],cluster_labels1)))\n",
    "    print('SIMLR - ' + str(ari(funcs[I].adata.obs.iloc[:,0],cluster_labels2)))\n",
    "    print('Seurat - ' + str(ari(funcs[I].adata.obs.iloc[:,0],cluster_labels3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "3000\n",
      "4000\n",
      "4500\n",
      "2500\n",
      "5000\n",
      "6000\n",
      "3500\n",
      "2000\n"
     ]
    }
   ],
   "source": [
    "C4=[]\n",
    "for i in range(len(funcs)):\n",
    "    adata = funcs[i].adata_raw.copy()\n",
    "    if i == 1:\n",
    "        adata.X[adata.X<1]=0\n",
    "        adata.X.eliminate_zeros()\n",
    "        \n",
    "    _,cl = SEURAT2(adata,nge[i],npc[i])\n",
    "    C4.append(cl)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C0=[]\n",
    "for i in range(len(funcs)):\n",
    "    print(i)\n",
    "    funcs[i].run(preprocessing=preproc[i])\n",
    "    funcs[i].hdbknn_clustering(npcs=15)\n",
    "    C0.append(funcs[i].adata.obs['hdbscan_clusters'].get_values())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "(C0,C1,C2,C3,C4) = pickle.load(open('paper_scripts/cluster_assignments_sc3_sim_seur_opt.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "\n",
    "S = []\n",
    "for I in range(9):\n",
    "    sam = funcs[I]\n",
    "    cl0 = C0[I]\n",
    "    cl1 = C1[I]\n",
    "    cl2 = C2[I]\n",
    "    cl3 = C3[I]\n",
    "    cl4 = C4[I]\n",
    "\n",
    "    CS = [cl0,cl1,cl2,cl3, cl4]\n",
    "    ann = sam.adata.obs.iloc[:,0].get_values()\n",
    "    annu,annuc = np.unique(sam.adata.obs.iloc[:,0],return_counts=True)\n",
    "\n",
    "    x=[]\n",
    "    scores = np.zeros((len(CS),annu.size))\n",
    "    \n",
    "    \n",
    "    co = colabeling(ann,ann)[0]\n",
    "    NUMERATOR2 = sp.special.binom(co,2).sum(0) - (sp.special.binom(co.sum(1),2).sum()*sp.special.binom(co.sum(0),2)) / sp.special.binom(cl0.size,2)\n",
    "    DENOMINATOR2 = (sp.special.binom(co.sum(1),2).sum()+sp.special.binom(co.sum(0),2).sum()) * 0.5 - (sp.special.binom(co.sum(1),2).sum()*sp.special.binom(co.sum(0),2).sum())/ sp.special.binom(cl0.size,2)        \n",
    "    gt = NUMERATOR2/DENOMINATOR2\n",
    "    \n",
    "    for m in range(len(CS)):\n",
    "        c = np.array(CS[m])\n",
    "        cu = np.unique(c)\n",
    "        co = colabeling(c,ann)[0]\n",
    "        NUMERATOR = sp.special.binom(co,2).sum(0) - (sp.special.binom(co.sum(1),2).sum()*sp.special.binom(co.sum(0),2)) / sp.special.binom(cl0.size,2)\n",
    "        DENOMINATOR = (sp.special.binom(co.sum(1),2).sum()+sp.special.binom(co.sum(0),2).sum()) * 0.5 - (sp.special.binom(co.sum(1),2).sum()*sp.special.binom(co.sum(0),2).sum())/ sp.special.binom(cl0.size,2)\n",
    "        scores[m,:] = (NUMERATOR / DENOMINATOR)# / (NUMERATOR2 / DENOMINATOR2)# * c.size / np.unique(ann,return_counts=True)[1]\n",
    "        #print((NUMERATOR2 / DENOMINATOR2).sum())\n",
    "    S.append(pd.DataFrame(data = np.hstack((np.append(annuc,annuc.sum())[:,None],np.vstack((scores.T,scores.T.sum(0))),np.append(gt,gt.sum())[:,None])), columns = ['# cells','SAM','SC3','SIMLR','Seurat', 'Seurat optimized', ' Ground truth'], index = np.append(annu,'ARI (Total)')))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['Darmanis','Wang','Baron1','Baron2','Baron3','Baron4','Koh','Segerstolpe','Muraro']\n",
    "with pd.ExcelWriter(\"/media/storage/dbox/Dropbox/paper_scripts/ARI_TABLES2.xlsx\") as writer:  \n",
    "    for i in range(len(S)):\n",
    "        S[i].index.name = names[i] + ' labels'\n",
    "        S[i].to_excel(writer,sheet_name=names[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING SAM\n",
      "Iteration: 0, Convergence: 0.4526962542729544\n",
      "Iteration: 1, Convergence: 0.12612906385641998\n",
      "Iteration: 2, Convergence: 0.07305737834954922\n",
      "Iteration: 3, Convergence: 0.021107561918671688\n",
      "Iteration: 4, Convergence: 0.008076236324138297\n",
      "Computing the UMAP embedding...\n",
      "Elapsed time: 3.384687662124634 seconds\n",
      "3000\n"
     ]
    }
   ],
   "source": [
    "sam=SAM()\n",
    "sam.load_data('schisto2.5_tpm.csv')\n",
    "sam.preprocess_data()\n",
    "sam.run()\n",
    "sam.louvain_clustering()\n",
    "\n",
    "pca,_ = SEURAT(sam.adata_raw.copy())\n",
    "import scipy as sp\n",
    "cl = sam.leiden_clustering(X=sp.sparse.csr_matrix(ut.dist_to_nn(ut.compute_distances(pca,'correlation'),20)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32706247385306214"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ari(cl,sam.adata.obs['louvain_clusters'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
